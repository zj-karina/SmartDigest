"""Enhanced news classifier with extended categories and relevance filtering."""

import time
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from transformers import pipeline
import torch
import warnings
warnings.filterwarnings('ignore')


class EnhancedNewsClassifier:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏."""
    
    def __init__(self, method: str = 'bge_large', relevance_threshold: float = 0.6):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
        
        Args:
            method: –ú–µ—Ç–æ–¥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            relevance_threshold: –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–Ω–∏–∂–µ = –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Å—Ç–∞—Ç—å—è)
        """
        self.method = method
        self.relevance_threshold = relevance_threshold
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
        self.categories = [
            'politics_domestic', 'politics_international', 'politics_elections',
            'business_markets', 'business_tech', 'business_economy', 
            'technology_ai', 'technology_software', 'technology_hardware',
            'sports_football', 'sports_other', 'sports_olympics',
            'entertainment_movies', 'entertainment_music', 'entertainment_tv',
            'health_medical', 'health_pandemic', 'health_mental',
            'science_research', 'science_climate', 'science_space',
            'world_conflicts', 'world_diplomacy', 'world_disasters',
            'crime_investigations', 'crime_courts', 'crime_terrorism',
            'education', 'transportation', 'environment', 'social_issues'
        ]
        
        # –û–ø–∏—Å–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ª—É—á—à–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.category_descriptions = {
            'politics_domestic': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–ª–∏—Ç–∏–∫–∞, –º–µ—Å—Ç–Ω—ã–µ –ø–æ–ª–∏—Ç–∏–∫–∏, –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è',
            'politics_international': '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞, –¥–∏–ø–ª–æ–º–∞—Ç–∏—è, –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∞–º–∏',
            'politics_elections': '–í—ã–±–æ—Ä—ã, –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è',
            
            'business_markets': '–§–æ–Ω–¥–æ–≤—ã–µ —Ä—ã–Ω–∫–∏, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏, —Ç–æ—Ä–≥–æ–≤–ª—è, —Ñ–∏–Ω–∞–Ω—Å—ã',
            'business_tech': '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏, —Å—Ç–∞—Ä—Ç–∞–ø—ã, –≤–µ–Ω—á—É—Ä–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏',
            'business_economy': '–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, –∏–Ω—Ñ–ª—è—Ü–∏—è, –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü–∞, –í–í–ü',
            
            'technology_ai': '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏',
            'technology_software': '–ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã',
            'technology_hardware': '–ö–æ–º–ø—å—é—Ç–µ—Ä—ã, —Å–º–∞—Ä—Ç—Ñ–æ–Ω—ã, –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã, —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞',
            
            'sports_football': '–§—É—Ç–±–æ–ª, —á–µ–º–ø–∏–æ–Ω–∞—Ç—ã, –º–∞—Ç—á–∏, —Ñ—É—Ç–±–æ–ª–∏—Å—Ç—ã',
            'sports_other': '–î—Ä—É–≥–∏–µ –≤–∏–¥—ã —Å–ø–æ—Ä—Ç–∞, —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è, —Å–ø–æ—Ä—Ç—Å–º–µ–Ω—ã',
            'sports_olympics': '–û–ª–∏–º–ø–∏–π—Å–∫–∏–µ –∏–≥—Ä—ã, –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è',
            
            'entertainment_movies': '–§–∏–ª—å–º—ã, –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ, –∞–∫—Ç–µ—Ä—ã, —Ä–µ–∂–∏—Å—Å–µ—Ä—ã',
            'entertainment_music': '–ú—É–∑—ã–∫–∞, –∫–æ–Ω—Ü–µ—Ä—Ç—ã, –º—É–∑—ã–∫–∞–Ω—Ç—ã, –∞–ª—å–±–æ–º—ã',
            'entertainment_tv': '–¢–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ, —Å–µ—Ä–∏–∞–ª—ã, —à–æ—É, —Ç–µ–ª–µ–≤–µ–¥—É—â–∏–µ',
            
            'health_medical': '–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –ª–µ—á–µ–Ω–∏–µ, –±–æ–ª—å–Ω–∏—Ü—ã, –≤—Ä–∞—á–∏',
            'health_pandemic': '–ü–∞–Ω–¥–µ–º–∏–∏, —ç–ø–∏–¥–µ–º–∏–∏, –≤–∏—Ä—É—Å—ã, –≤–∞–∫—Ü–∏–Ω—ã',
            'health_mental': '–ü—Å–∏—Ö–∏—á–µ—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ, —Å—Ç—Ä–µ—Å—Å, –¥–µ–ø—Ä–µ—Å—Å–∏—è',
            
            'science_research': '–ù–∞—É—á–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –æ—Ç–∫—Ä—ã—Ç–∏—è, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
            'science_climate': '–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–ª–∏–º–∞—Ç–∞, —ç–∫–æ–ª–æ–≥–∏—è, –≥–ª–æ–±–∞–ª—å–Ω–æ–µ –ø–æ—Ç–µ–ø–ª–µ–Ω–∏–µ',
            'science_space': '–ö–æ—Å–º–æ—Å, –∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è, –∫–æ—Å–º–∏—á–µ—Å–∫–∏–µ –º–∏—Å—Å–∏–∏',
            
            'world_conflicts': '–í–æ–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã, –≤–æ–π–Ω—ã, —Ç–µ—Ä—Ä–æ—Ä–∏–∑–º',
            'world_diplomacy': '–î–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è, –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã, —Å–æ–≥–ª–∞—à–µ–Ω–∏—è',
            'world_disasters': '–ü—Ä–∏—Ä–æ–¥–Ω—ã–µ –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ—ã, –∞–≤–∞—Ä–∏–∏, —á—Ä–µ–∑–≤—ã—á–∞–π–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏',
            
            'crime_investigations': '–†–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π, –ø–æ–ª–∏—Ü–∏—è, –¥–µ—Ç–µ–∫—Ç–∏–≤—ã',
            'crime_courts': '–°—É–¥–µ–±–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã, –ø—Ä–∏–≥–æ–≤–æ—Ä—ã, –ø—Ä–∞–≤–æ—Å—É–¥–∏–µ',
            'crime_terrorism': '–¢–µ—Ä—Ä–æ—Ä–∏–∑–º, —ç–∫—Å—Ç—Ä–µ–º–∏–∑–º, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
            
            'education': '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—ã, —à–∫–æ–ª—ã, —Å—Ç—É–¥–µ–Ω—Ç—ã',
            'transportation': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç, –∞–≤—Ç–æ–º–æ–±–∏–ª–∏, –∞–≤–∏–∞—Ü–∏—è, –∂–µ–ª–µ–∑–Ω—ã–µ –¥–æ—Ä–æ–≥–∏',
            'environment': '–û–∫—Ä—É–∂–∞—é—â–∞—è —Å—Ä–µ–¥–∞, –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ, –ø—Ä–∏—Ä–æ–¥–∞',
            'social_issues': '–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, –ø—Ä–∞–≤–∞ —á–µ–ª–æ–≤–µ–∫–∞, –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ'
        }
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        self.irrelevant_keywords = [
            'advertisement', 'sponsored', 'promotion', 'casino', 'gambling',
            'adult content', 'explicit', 'nsfw', 'clickbait', 'fake news',
            'horoscope', 'astrology', 'fortune telling', 'lottery',
            'weight loss miracle', 'get rich quick', 'earn money fast',
            'celebrity gossip', 'tabloid', 'scandal', 'rumor',
            'spam', 'scam', 'fraud', 'phishing', 'malware'
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        self.relevant_keywords = [
            'breaking news', 'developing story', 'latest update', 'official statement',
            'government', 'president', 'minister', 'congress', 'parliament',
            'company', 'market', 'stock', 'economy', 'financial',
            'research', 'study', 'scientist', 'discovery', 'innovation',
            'health', 'medical', 'treatment', 'vaccine', 'disease',
            'technology', 'artificial intelligence', 'software', 'hardware',
            'sports', 'championship', 'tournament', 'athlete', 'team',
            'climate', 'environment', 'disaster', 'emergency'
        ]
        
        self.models = {
            'bge_large': 'BAAI/bge-large-en-v1.5',
            'bge_base': 'BAAI/bge-base-en-v1.5', 
            'e5_large': 'intfloat/e5-large-v2',
            'e5_base': 'intfloat/e5-base-v2',
            'mpnet': 'sentence-transformers/all-mpnet-base-v2',
            'minilm': 'all-MiniLM-L6-v2'
        }
        
        self.model = None
        self.classifier = None
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
        if self.model is not None:
            return
            
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {self.method}...")
        
        if self.method == 'zero_shot':
            device = 0 if torch.cuda.is_available() else -1
            self.classifier = pipeline(
                "zero-shot-classification", 
                model="facebook/bart-large-mnli",
                device=device
            )
        elif self.method in self.models:
            model_name = self.models[self.method]
            self.model = SentenceTransformer(model_name)
        else:
            # Fallback –º–æ–¥–µ–ª—å
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def _check_relevance(self, text: str) -> Tuple[bool, float]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç—å–∏.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[is_relevant, confidence]
        """
        text_lower = text.lower()
        
        # –ü–æ–¥—Å—á–µ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        irrelevant_score = sum(1 for keyword in self.irrelevant_keywords if keyword in text_lower)
        
        # –ü–æ–¥—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        relevant_score = sum(1 for keyword in self.relevant_keywords if keyword in text_lower)
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        if irrelevant_score > 2:  # –ú–Ω–æ–≥–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–ª–æ–≤
            return False, 0.1
        
        if relevant_score == 0 and len(text.split()) < 10:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–ª–æ–≤
            return False, 0.3
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞
        words = text.split()
        if len(words) < 5:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            return False, 0.2
        
        if len(words) > 500:  # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–≤–æ–∑–º–æ–∂–Ω–æ spam)
            return False, 0.2
        
        # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        if relevant_score > 0:
            confidence = min(0.9, 0.5 + (relevant_score * 0.1))
            return True, confidence
        
        # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        return True, 0.7
    
    def classify_single(self, text: str) -> Dict[str, Any]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ç–∞—Ç—å—é.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        self._load_model()
        start_time = time.time()
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        is_relevant, relevance_confidence = self._check_relevance(text)
        
        result = {
            'is_relevant': is_relevant,
            'relevance_confidence': relevance_confidence,
            'method': self.method,
            'time': time.time() - start_time
        }
        
        if not is_relevant:
            result.update({
                'category': 'irrelevant',
                'confidence': 0.0
            })
            return result
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if self.method == 'zero_shot':
            classification_result = self.classifier(text, self.categories)
            result.update({
                'category': classification_result['labels'][0],
                'confidence': classification_result['scores'][0]
            })
        else:
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            text_emb = self.model.encode([text])
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ E5 –º–æ–¥–µ–ª–µ–π
            if 'e5' in self.method:
                text_emb = self.model.encode([f"query: {text}"])
                cat_embs = self.model.encode([f"passage: {desc}" for desc in self.category_descriptions.values()])
            else:
                cat_embs = self.model.encode(list(self.category_descriptions.values()))
            
            similarities = cosine_similarity(text_emb, cat_embs)[0]
            best_idx = np.argmax(similarities)
            
            result.update({
                'category': self.categories[best_idx],
                'confidence': float(similarities[best_idx])
            })
        
        result['time'] = time.time() - start_time
        return result
    
    def classify_batch(self, news_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π.
        
        Args:
            news_list: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å 'title' –∏ 'description'
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        print(f"üóÇÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è {len(news_list)} —Å—Ç–∞—Ç–µ–π —Å {self.method}...")
        
        results = []
        relevant_count = 0
        
        for i, news in enumerate(news_list):
            if i % 20 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(news_list)}...")
            
            text = f"{news['title']}. {news.get('description', '')}"
            classification = self.classify_single(text)
            
            if classification['is_relevant']:
                relevant_count += 1
            
            result = news.copy()
            result.update(classification)
            results.append(result)
        
        print(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {relevant_count}/{len(news_list)} ({relevant_count/len(news_list)*100:.1f}%)")
        
        return results
    
    def get_category_hierarchy(self) -> Dict[str, List[str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ –∏—Ö –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        """
        return {
            'politics': ['politics_domestic', 'politics_international', 'politics_elections'],
            'business': ['business_markets', 'business_tech', 'business_economy'],
            'technology': ['technology_ai', 'technology_software', 'technology_hardware'],
            'sports': ['sports_football', 'sports_other', 'sports_olympics'],
            'entertainment': ['entertainment_movies', 'entertainment_music', 'entertainment_tv'],
            'health': ['health_medical', 'health_pandemic', 'health_mental'],
            'science': ['science_research', 'science_climate', 'science_space'],
            'world': ['world_conflicts', 'world_diplomacy', 'world_disasters'],
            'crime': ['crime_investigations', 'crime_courts', 'crime_terrorism'],
            'society': ['education', 'transportation', 'environment', 'social_issues']
        }
    
    def get_main_category(self, subcategory: str) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
        
        Args:
            subcategory: –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è
            
        Returns:
            –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        """
        hierarchy = self.get_category_hierarchy()
        for main_cat, sub_cats in hierarchy.items():
            if subcategory in sub_cats:
                return main_cat
        return 'other'
    
    @staticmethod
    def get_available_methods() -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        return ['bge_large', 'bge_base', 'e5_large', 'e5_base', 'mpnet', 'minilm', 'zero_shot'] 