"""MongoDB integration for SmartDigest pipeline."""

import os
import hashlib
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
from pymongo import MongoClient, ASCENDING, DESCENDING
from pymongo.collection import Collection
from pymongo.database import Database
import json
import logging

logger = logging.getLogger(__name__)


class DatabaseManager:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ —Å MongoDB."""
    
    def __init__(self, connection_string: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ë–î.
        
        Args:
            connection_string: –°—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB
        """
        self.connection_string = connection_string or os.getenv('MONGODB_CONNECTION_STRING')
        if not self.connection_string:
            raise ValueError("MongoDB connection string –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        self.client: Optional[MongoClient] = None
        self.db: Optional[Database] = None
        self._connect()
        
    def _connect(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB."""
        try:
            self.client = MongoClient(self.connection_string)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Prod –≤–º–µ—Å—Ç–æ smartdigest
            self.db = self.client.Prod
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            self.client.admin.command('ping')
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–∞–≤–∞ (–æ—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è —Ä–µ–∂–∏–º–∞ —Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏—è)
            # try:
            #     self._create_indexes()
            # except Exception as e:
            #     logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã: {e}")
            #     logger.info("üìù –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∏–Ω–¥–µ–∫—Å–æ–≤")
            logger.info("üìù –ò–Ω–¥–µ–∫—Å—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ —Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏—è")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB: {e}")
            raise
    
    def _create_indexes(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤."""
        collections = {
            'articles': [
                ('url', ASCENDING),
                ('title_hash', ASCENDING),
                ('collected_at', DESCENDING),
                ('source', ASCENDING),
                ('category', ASCENDING)
            ],
            'digests': [
                ('created_at', DESCENDING),
                ('language', ASCENDING),
                ('pipeline_version', ASCENDING)
            ],
            'processing_history': [
                ('article_id', ASCENDING),
                ('processed_at', DESCENDING),
                ('pipeline_version', ASCENDING)
            ]
        }
        
        for collection_name, indexes in collections.items():
            collection = self.db[collection_name]
            for index_fields in indexes:
                collection.create_index([index_fields])
    
    def _generate_article_hash(self, article: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö—ç—à –¥–ª—è —Å—Ç–∞—Ç—å–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        content = f"{article.get('title', '')}{article.get('description', '')}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def save_articles(self, articles: List[Dict[str, Any]], batch_size: int = 100) -> List[str]:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—å–∏ –≤ –ë–î —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
        
        Args:
            articles: –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        """
        if not articles:
            return []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é news_raw –≤ –±–∞–∑–µ Prod
        collection = self.db.news_raw
        saved_ids = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å–∏ –±–∞—Ç—á–∞–º–∏
        for i in range(0, len(articles), batch_size):
            batch = articles[i:i + batch_size]
            processed_batch = []
            
            for article in batch:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö—ç—à –∑–∞–≥–æ–ª–æ–≤–∫–∞
                title_hash = self._generate_article_hash(article)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç
                existing = collection.find_one({'title_hash': title_hash})
                if existing:
                    logger.info(f"–î—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω: {article.get('title', '')[:50]}...")
                    saved_ids.append(str(existing['_id']))
                    continue
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
                document = {
                    'title': article.get('title', ''),
                    'description': article.get('description', ''),
                    'url': article.get('url', ''),
                    'source': article.get('source', ''),
                    'published': article.get('published'),
                    'title_hash': title_hash,
                    'collected_at': datetime.now(timezone.utc),
                    'language': article.get('language'),
                    'category': article.get('category'),
                    'is_relevant': article.get('is_relevant', True),
                    'classification_confidence': article.get('classification_confidence'),
                    'raw_data': article  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                }
                
                processed_batch.append(document)
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á
            if processed_batch:
                try:
                    result = collection.insert_many(processed_batch)
                    batch_ids = [str(id_) for id_ in result.inserted_ids]
                    saved_ids.extend(batch_ids)
                    logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(processed_batch)} —Å—Ç–∞—Ç–µ–π –≤ –±–∞—Ç—á–µ")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞—Ç—á–∞: {e}")
        
        logger.info(f"–í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ/–Ω–∞–π–¥–µ–Ω–æ {len(saved_ids)} —Å—Ç–∞—Ç–µ–π")
        return saved_ids
    
    def get_articles(self, 
                    limit: int = 100,
                    category: Optional[str] = None,
                    source: Optional[str] = None,
                    is_relevant: Optional[bool] = None,
                    date_from: Optional[datetime] = None) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –∏–∑ –ë–î —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π.
        
        Args:
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π
            category: –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            source: –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
            is_relevant: –§–∏–ª—å—Ç—Ä –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            date_from: –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ (–æ—Ç)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é news_raw –≤ –±–∞–∑–µ Prod
        collection = self.db.news_raw
        
        # –°—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
        query = {}
        
        if category:
            query['meta.labels'] = {'$in': [category]}
        
        if source:
            query['url'] = {'$regex': source, '$options': 'i'}
        
        if date_from:
            query['publish_date'] = {'$gte': date_from}
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—å–∏
        cursor = collection.find(query).sort('publish_date', -1).limit(limit)
        return list(cursor)
    
    def save_digest(self, digest: Dict[str, Any], pipeline_config: Dict[str, Any]) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–æ—Ç–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ –ë–î.
        
        Args:
            digest: –î–∞–Ω–Ω—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞
            pipeline_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
            
        Returns:
            ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        """
        collection = self.db.digests
        
        document = {
            'digest_data': digest,
            'pipeline_config': pipeline_config,
            'created_at': datetime.now(timezone.utc),
            'language': digest.get('language', 'unknown'),
            'events_count': len(digest.get('items', [])),
            'articles_processed': digest.get('articles_processed', 0),
            'pipeline_version': pipeline_config.get('version', '1.0')
        }
        
        result = collection.insert_one(document)
        digest_id = str(result.inserted_id)
        
        logger.info(f"–î–∞–π–¥–∂–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å ID: {digest_id}")
        return digest_id
    
    def get_digests(self, limit: int = 10, language: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã.
        
        Args:
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
            language: –§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
        """
        collection = self.db.digests
        
        filter_query = {}
        if language:
            filter_query['language'] = language
        
        cursor = collection.find(filter_query).sort('created_at', DESCENDING).limit(limit)
        digests = list(cursor)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ObjectId –≤ —Å—Ç—Ä–æ–∫–∏
        for digest in digests:
            digest['_id'] = str(digest['_id'])
        
        return digests
    
    def mark_articles_processed(self, article_ids: List[str], pipeline_config: Dict[str, Any]):
        """
        –û—Ç–º–µ—á–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ.
        
        Args:
            article_ids: –°–ø–∏—Å–æ–∫ ID —Å—Ç–∞—Ç–µ–π
            pipeline_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        collection = self.db.processing_history
        
        documents = []
        for article_id in article_ids:
            documents.append({
                'article_id': article_id,
                'processed_at': datetime.now(timezone.utc),
                'pipeline_version': pipeline_config.get('version', '1.0'),
                'pipeline_config': pipeline_config
            })
        
        if documents:
            collection.insert_many(documents)
            logger.info(f"–û—Ç–º–µ—á–µ–Ω–æ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ {len(documents)} —Å—Ç–∞—Ç–µ–π")
    
    def update_article_relevance(self, article_id: str, is_relevant: bool, confidence: float = 0.0):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏.
        
        Args:
            article_id: ID —Å—Ç–∞—Ç—å–∏
            is_relevant: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç—å–∏
            confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        collection = self.db.articles
        
        result = collection.update_one(
            {'_id': article_id},
            {
                '$set': {
                    'is_relevant': is_relevant,
                    'relevance_confidence': confidence,
                    'relevance_updated_at': datetime.now(timezone.utc)
                }
            }
        )
        
        if result.modified_count > 0:
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç—å–∏ {article_id}: {is_relevant}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        stats = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—å—è–º
        articles_collection = self.db.articles
        stats['total_articles'] = articles_collection.count_documents({})
        stats['relevant_articles'] = articles_collection.count_documents({'is_relevant': True})
        stats['irrelevant_articles'] = articles_collection.count_documents({'is_relevant': False})
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        pipeline = [
            {'$group': {'_id': '$category', 'count': {'$sum': 1}}},
            {'$sort': {'count': -1}}
        ]
        stats['categories'] = list(articles_collection.aggregate(pipeline))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        pipeline = [
            {'$group': {'_id': '$source', 'count': {'$sum': 1}}},
            {'$sort': {'count': -1}}
        ]
        stats['sources'] = list(articles_collection.aggregate(pipeline))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞–º
        digests_collection = self.db.digests
        stats['total_digests'] = digests_collection.count_documents({})
        
        return stats
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î."""
        if self.client:
            self.client.close()
            logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å MongoDB –∑–∞–∫—Ä—ã—Ç–æ") 